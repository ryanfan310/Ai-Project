{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dS0slCy97LD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import warnings\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.cuda.amp import autocast as autocast\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V97x1HXqbDcm",
        "outputId": "5b289387-b585-4cf8-88e2-de1e2e74bf89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building test datasets...\n",
            "building train datasets...\n",
            "saving datasets...\n",
            "datasets saved at ./data/sort-of-clevr.pickle\n"
          ]
        }
      ],
      "source": [
        "t_subtype = -1\n",
        "\n",
        "train_size = 9800\n",
        "test_size = 200\n",
        "img_size = 75\n",
        "size = 5\n",
        "question_size = 18  ## 2 x (6 for one-hot vector of color), 3 for question type, 3 for question subtype\n",
        "q_type_idx = 12\n",
        "sub_q_type_idx = 15\n",
        "\"\"\"Answer : [yes, no, rectangle, circle, r, g, b, o, k, y]\"\"\"\n",
        "\n",
        "nb_questions = 10\n",
        "dirs = './data'\n",
        "\n",
        "colors = [\n",
        "    (0,0,255),##r\n",
        "    (0,255,0),##g\n",
        "    (255,0,0),##b\n",
        "    (0,156,255),##o\n",
        "    (128,128,128),##k\n",
        "    (0,255,255)##y\n",
        "]\n",
        "\n",
        "\n",
        "try:\n",
        "    os.makedirs(dirs)\n",
        "except:\n",
        "    print('directory {} already exists'.format(dirs))\n",
        "\n",
        "\n",
        "def center_generate(objects):\n",
        "    while True:\n",
        "        pas = True\n",
        "        center = np.random.randint(0+size, img_size - size, 2)        \n",
        "        if len(objects) > 0:\n",
        "            for name,c,shape in objects:\n",
        "                if ((center - c) ** 2).sum() < ((size * 2) ** 2):\n",
        "                    pas = False\n",
        "        if pas:\n",
        "            return center\n",
        "\n",
        "\n",
        "def build_dataset():\n",
        "    objects = []\n",
        "    img = np.ones((img_size,img_size,3)) * 255\n",
        "    for color_id,color in enumerate(colors):  \n",
        "        center = center_generate(objects)\n",
        "        if random.random()<0.5:\n",
        "            start = (center[0]-size, center[1]-size)\n",
        "            end = (center[0]+size, center[1]+size)\n",
        "            cv2.rectangle(img, start, end, color, -1)\n",
        "            objects.append((color_id,center,'r'))\n",
        "        else:\n",
        "            center_ = (center[0], center[1])\n",
        "            cv2.circle(img, center_, size, color, -1)\n",
        "            objects.append((color_id,center,'c'))\n",
        "\n",
        "\n",
        "    ternary_questions = []\n",
        "    binary_questions = []\n",
        "    norel_questions = []\n",
        "    ternary_answers = []\n",
        "    binary_answers = []\n",
        "    norel_answers = []\n",
        "    \"\"\"Non-relational questions\"\"\"\n",
        "    for _ in range(nb_questions):\n",
        "        question = np.zeros((question_size))\n",
        "        color = random.randint(0,5)\n",
        "        question[color] = 1\n",
        "        question[q_type_idx] = 1\n",
        "        subtype = random.randint(0,2)\n",
        "        question[subtype+sub_q_type_idx] = 1\n",
        "        norel_questions.append(question)\n",
        "        \"\"\"Answer : [yes, no, rectangle, circle, r, g, b, o, k, y]\"\"\"\n",
        "        if subtype == 0:\n",
        "            \"\"\"query shape->rectangle/circle\"\"\"\n",
        "            if objects[color][2] == 'r':\n",
        "                answer = 2\n",
        "            else:\n",
        "                answer = 3\n",
        "\n",
        "        elif subtype == 1:\n",
        "            \"\"\"query horizontal position->yes/no\"\"\"\n",
        "            if objects[color][1][0] < img_size / 2:\n",
        "                answer = 0\n",
        "            else:\n",
        "                answer = 1\n",
        "\n",
        "        elif subtype == 2:\n",
        "            \"\"\"query vertical position->yes/no\"\"\"\n",
        "            if objects[color][1][1] < img_size / 2:\n",
        "                answer = 0\n",
        "            else:\n",
        "                answer = 1\n",
        "        norel_answers.append(answer)\n",
        "    \n",
        "    \"\"\"Binary Relational questions\"\"\"\n",
        "    for _ in range(nb_questions):\n",
        "        question = np.zeros((question_size))\n",
        "        color = random.randint(0,5)\n",
        "        question[color] = 1\n",
        "        question[q_type_idx+1] = 1\n",
        "        subtype = random.randint(0,2)\n",
        "        question[subtype+sub_q_type_idx] = 1\n",
        "        binary_questions.append(question)\n",
        "\n",
        "        if subtype == 0:\n",
        "            \"\"\"closest-to->rectangle/circle\"\"\"\n",
        "            my_obj = objects[color][1]\n",
        "            dist_list = [((my_obj - obj[1]) ** 2).sum() for obj in objects]\n",
        "            dist_list[dist_list.index(0)] = 999\n",
        "            closest = dist_list.index(min(dist_list))\n",
        "            if objects[closest][2] == 'r':\n",
        "                answer = 2\n",
        "            else:\n",
        "                answer = 3\n",
        "                \n",
        "        elif subtype == 1:\n",
        "            \"\"\"furthest-from->rectangle/circle\"\"\"\n",
        "            my_obj = objects[color][1]\n",
        "            dist_list = [((my_obj - obj[1]) ** 2).sum() for obj in objects]\n",
        "            furthest = dist_list.index(max(dist_list))\n",
        "            if objects[furthest][2] == 'r':\n",
        "                answer = 2\n",
        "            else:\n",
        "                answer = 3\n",
        "\n",
        "        elif subtype == 2:\n",
        "            \"\"\"count->1~6\"\"\"\n",
        "            my_obj = objects[color][2]\n",
        "            count = -1\n",
        "            for obj in objects:\n",
        "                if obj[2] == my_obj:\n",
        "                    count +=1 \n",
        "            answer = count+4\n",
        "\n",
        "        binary_answers.append(answer)\n",
        "\n",
        "    \"\"\"Ternary Relational questions\"\"\"\n",
        "    for _ in range(nb_questions):\n",
        "        question = np.zeros((question_size))\n",
        "        rnd_colors = np.random.permutation(np.arange(5))\n",
        "        # 1st object\n",
        "        color1 = rnd_colors[0]\n",
        "        question[color1] = 1\n",
        "        # 2nd object\n",
        "        color2 = rnd_colors[1]\n",
        "        question[6 + color2] = 1\n",
        "\n",
        "        question[q_type_idx + 2] = 1\n",
        "        \n",
        "        if t_subtype >= 0 and t_subtype < 3:\n",
        "            subtype = t_subtype\n",
        "        else:\n",
        "            subtype = random.randint(0, 2)\n",
        "\n",
        "        question[subtype+sub_q_type_idx] = 1\n",
        "        ternary_questions.append(question)\n",
        "\n",
        "        # get coordiantes of object from question\n",
        "        A = objects[color1][1]\n",
        "        B = objects[color2][1]\n",
        "\n",
        "        if subtype == 0:\n",
        "            \"\"\"between->1~4\"\"\"\n",
        "\n",
        "            between_count = 0 \n",
        "            # check is any objects lies inside the box\n",
        "            for other_obj in objects:\n",
        "                # skip object A and B\n",
        "                if (other_obj[0] == color1) or (other_obj[0] == color2):\n",
        "                    continue\n",
        "\n",
        "                # Get x and y coordinate of third object\n",
        "                other_objx = other_obj[1][0]\n",
        "                other_objy = other_obj[1][1]\n",
        "\n",
        "                if (A[0] <= other_objx <= B[0] and A[1] <= other_objy <= B[1]) or \\\n",
        "                   (A[0] <= other_objx <= B[0] and B[1] <= other_objy <= A[1]) or \\\n",
        "                   (B[0] <= other_objx <= A[0] and B[1] <= other_objy <= A[1]) or \\\n",
        "                   (B[0] <= other_objx <= A[0] and A[1] <= other_objy <= B[1]):\n",
        "                    between_count += 1\n",
        "\n",
        "            answer = between_count + 4\n",
        "        elif subtype == 1:\n",
        "            \"\"\"is-on-band->yes/no\"\"\"\n",
        "            \n",
        "            grace_threshold = 12  # half of the size of objects\n",
        "            epsilon = 1e-10  \n",
        "            m = (B[1]-A[1])/((B[0]-A[0]) + epsilon ) # add epsilon to prevent dividing by zero\n",
        "            c = A[1] - (m*A[0])\n",
        "\n",
        "            answer = 1  # default answer is 'no'\n",
        "\n",
        "            # check if any object lies on/close the line between object A and object B\n",
        "            for other_obj in objects:\n",
        "                # skip object A and B\n",
        "                if (other_obj[0] == color1) or (other_obj[0] == color2):\n",
        "                    continue\n",
        "\n",
        "                other_obj_pos = other_obj[1]\n",
        "                \n",
        "                # y = mx + c\n",
        "                y = (m*other_obj_pos[0]) + c\n",
        "                if (y - grace_threshold)  <= other_obj_pos[1] <= (y + grace_threshold):\n",
        "                    answer = 0\n",
        "        elif subtype == 2:\n",
        "            \"\"\"count-obtuse-triangles->1~6\"\"\"\n",
        "\n",
        "            obtuse_count = 0\n",
        "\n",
        "            # disable warnings\n",
        "            # the angle computation may fail if the points are on a line\n",
        "            warnings.filterwarnings(\"ignore\")\n",
        "            for other_obj in objects:\n",
        "                # skip object A and B\n",
        "                if (other_obj[0] == color1) or (other_obj[0] == color2):\n",
        "                    continue\n",
        "\n",
        "                # get position of 3rd object\n",
        "                C = other_obj[1]\n",
        "                # edge length\n",
        "                a = np.linalg.norm(B - C)\n",
        "                b = np.linalg.norm(C - A)\n",
        "                c = np.linalg.norm(A - B)\n",
        "                # angles by law of cosine\n",
        "                alpha = np.rad2deg(np.arccos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c)))\n",
        "                beta = np.rad2deg(np.arccos((a ** 2 + c ** 2 - b ** 2) / (2 * a * c)))\n",
        "                gamma = np.rad2deg(np.arccos((a ** 2 + b ** 2 - c ** 2) / (2 * a * b)))\n",
        "                max_angle = max(alpha, beta, gamma)\n",
        "                if max_angle >= 90 and max_angle < 180:\n",
        "                    obtuse_count += 1\n",
        "\n",
        "            warnings.filterwarnings(\"default\")\n",
        "            answer = obtuse_count + 4\n",
        "\n",
        "        ternary_answers.append(answer)\n",
        "\n",
        "    ternary_relations = (ternary_questions, ternary_answers)\n",
        "    binary_relations = (binary_questions, binary_answers)\n",
        "    norelations = (norel_questions, norel_answers)\n",
        "    \n",
        "    img = img/255.\n",
        "    dataset = (img, objects, ternary_relations, binary_relations, norelations)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "print('building test datasets...')\n",
        "test_datasets = [build_dataset() for _ in range(test_size)]\n",
        "print('building train datasets...')\n",
        "train_datasets = [build_dataset() for _ in range(train_size)]\n",
        "\n",
        "print('saving datasets...')\n",
        "filename = os.path.join(dirs,'sort-of-clevr.pickle')\n",
        "with  open(filename, 'wb') as f:\n",
        "    pickle.dump((train_datasets, test_datasets), f)\n",
        "print('datasets saved at {}'.format(filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk4ytmdUbDcn"
      },
      "outputs": [],
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, inchannel, outchannel, stride=1):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.left = nn.Sequential(\n",
        "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(outchannel),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(outchannel)\n",
        "        )\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or inchannel != outchannel:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(outchannel)\n",
        "            )\n",
        "            \n",
        "    def forward(self, x):\n",
        "        out = self.left(x)\n",
        "        out = out + self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5-mV-gFbDco",
        "outputId": "b119f9e7-8ea6-471f-86e5-261a6edddb2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 75, 75]             864\n",
            "       BatchNorm2d-2           [-1, 32, 75, 75]              64\n",
            "              ReLU-3           [-1, 32, 75, 75]               0\n",
            "            Conv2d-4           [-1, 32, 75, 75]           9,216\n",
            "       BatchNorm2d-5           [-1, 32, 75, 75]              64\n",
            "              ReLU-6           [-1, 32, 75, 75]               0\n",
            "            Conv2d-7           [-1, 32, 75, 75]           9,216\n",
            "       BatchNorm2d-8           [-1, 32, 75, 75]              64\n",
            "          ResBlock-9           [-1, 32, 75, 75]               0\n",
            "           Conv2d-10           [-1, 32, 75, 75]           9,216\n",
            "      BatchNorm2d-11           [-1, 32, 75, 75]              64\n",
            "             ReLU-12           [-1, 32, 75, 75]               0\n",
            "           Conv2d-13           [-1, 32, 75, 75]           9,216\n",
            "      BatchNorm2d-14           [-1, 32, 75, 75]              64\n",
            "         ResBlock-15           [-1, 32, 75, 75]               0\n",
            "           Conv2d-16           [-1, 48, 38, 38]          13,824\n",
            "      BatchNorm2d-17           [-1, 48, 38, 38]              96\n",
            "             ReLU-18           [-1, 48, 38, 38]               0\n",
            "           Conv2d-19           [-1, 48, 38, 38]          20,736\n",
            "      BatchNorm2d-20           [-1, 48, 38, 38]              96\n",
            "           Conv2d-21           [-1, 48, 38, 38]           1,536\n",
            "      BatchNorm2d-22           [-1, 48, 38, 38]              96\n",
            "         ResBlock-23           [-1, 48, 38, 38]               0\n",
            "           Conv2d-24           [-1, 48, 38, 38]          20,736\n",
            "      BatchNorm2d-25           [-1, 48, 38, 38]              96\n",
            "             ReLU-26           [-1, 48, 38, 38]               0\n",
            "           Conv2d-27           [-1, 48, 38, 38]          20,736\n",
            "      BatchNorm2d-28           [-1, 48, 38, 38]              96\n",
            "         ResBlock-29           [-1, 48, 38, 38]               0\n",
            "           Conv2d-30           [-1, 64, 19, 19]          27,648\n",
            "      BatchNorm2d-31           [-1, 64, 19, 19]             128\n",
            "             ReLU-32           [-1, 64, 19, 19]               0\n",
            "           Conv2d-33           [-1, 64, 19, 19]          36,864\n",
            "      BatchNorm2d-34           [-1, 64, 19, 19]             128\n",
            "           Conv2d-35           [-1, 64, 19, 19]           3,072\n",
            "      BatchNorm2d-36           [-1, 64, 19, 19]             128\n",
            "         ResBlock-37           [-1, 64, 19, 19]               0\n",
            "           Conv2d-38           [-1, 64, 19, 19]          36,864\n",
            "      BatchNorm2d-39           [-1, 64, 19, 19]             128\n",
            "             ReLU-40           [-1, 64, 19, 19]               0\n",
            "           Conv2d-41           [-1, 64, 19, 19]          36,864\n",
            "      BatchNorm2d-42           [-1, 64, 19, 19]             128\n",
            "         ResBlock-43           [-1, 64, 19, 19]               0\n",
            "           Conv2d-44           [-1, 96, 10, 10]          55,296\n",
            "      BatchNorm2d-45           [-1, 96, 10, 10]             192\n",
            "             ReLU-46           [-1, 96, 10, 10]               0\n",
            "           Conv2d-47           [-1, 96, 10, 10]          82,944\n",
            "      BatchNorm2d-48           [-1, 96, 10, 10]             192\n",
            "           Conv2d-49           [-1, 96, 10, 10]           6,144\n",
            "      BatchNorm2d-50           [-1, 96, 10, 10]             192\n",
            "         ResBlock-51           [-1, 96, 10, 10]               0\n",
            "           Conv2d-52           [-1, 96, 10, 10]          82,944\n",
            "      BatchNorm2d-53           [-1, 96, 10, 10]             192\n",
            "             ReLU-54           [-1, 96, 10, 10]               0\n",
            "           Conv2d-55           [-1, 96, 10, 10]          82,944\n",
            "      BatchNorm2d-56           [-1, 96, 10, 10]             192\n",
            "         ResBlock-57           [-1, 96, 10, 10]               0\n",
            "        AvgPool2d-58             [-1, 96, 5, 5]               0\n",
            "================================================================\n",
            "Total params: 569,280\n",
            "Trainable params: 569,280\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 31.51\n",
            "Params size (MB): 2.17\n",
            "Estimated Total Size (MB): 33.75\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "class ConvInputModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvInputModel, self).__init__()\n",
        "        self.inchannel = 32\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, self.inchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(self.inchannel),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer1 = self.make_layer(ResBlock, 32, 2, stride=1)\n",
        "        self.layer2 = self.make_layer(ResBlock, 48, 2, stride=2)\n",
        "        self.layer3 = self.make_layer(ResBlock, 64, 2, stride=2) \n",
        "        self.layer4 = self.make_layer(ResBlock, 96, 2, stride=2)\n",
        "        self.pool = nn.AvgPool2d(2)\n",
        "    \n",
        "    def make_layer(self, block, channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.inchannel, channels, stride))\n",
        "            self.inchannel = channels\n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, img):\n",
        "        x = self.conv1(img)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "summary(ConvInputModel(), (3, 75, 75), device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc5EXTZIbDco"
      },
      "outputs": [],
      "source": [
        "class FCOutputModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FCOutputModel, self).__init__()\n",
        "\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9XxmXQ1-EtA"
      },
      "outputs": [],
      "source": [
        "class RN(nn.Module):\n",
        "    def __init__(self, relation_type='ternary', batch_size=64, lr=0.0001, device='cpu'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = ConvInputModel()\n",
        "        self.conv_size = (96, 5, 5)\n",
        "        self.device = device\n",
        "        self.relation_type = relation_type\n",
        "        \n",
        "        if self.relation_type == 'ternary':\n",
        "            ##(number of filters per object+coordinate of object)*3+question vector\n",
        "            self.g_fc1 = nn.Linear((self.conv_size[0] + 2) * 3 + 18, 256)\n",
        "        else:\n",
        "            ##(number of filters per object+coordinate of object)*2+question vector\n",
        "            self.g_fc1 = nn.Linear((self.conv_size[0] + 2) * 2 + 18, 256)\n",
        "\n",
        "        self.g_fc2 = nn.Linear(256, 256)\n",
        "        self.g_fc3 = nn.Linear(256, 256)\n",
        "        self.g_fc4 = nn.Linear(256, 256)\n",
        "\n",
        "        self.f_fc1 = nn.Linear(256, 256)\n",
        "\n",
        "        self.coord_oi = torch.FloatTensor(batch_size, 2).to(self.device)\n",
        "        self.coord_oj = torch.FloatTensor(batch_size, 2).to(self.device)\n",
        "\n",
        "        self.coord_oi = Variable(self.coord_oi)\n",
        "        self.coord_oj = Variable(self.coord_oj)\n",
        "\n",
        "        # prepare coord tensor\n",
        "        def cvt_coord(i):\n",
        "            return [(i / 5 - 2) / 2., (i % 5 - 2) / 2.]\n",
        "        \n",
        "        self.coord_tensor = torch.FloatTensor(batch_size, 25, 2).to(self.device)\n",
        "        self.coord_tensor = Variable(self.coord_tensor)\n",
        "        np_coord_tensor = np.zeros((batch_size, 25, 2))\n",
        "        for i in range(25):\n",
        "            np_coord_tensor[:, i, :] = np.array(cvt_coord(i))\n",
        "        self.coord_tensor.data.copy_(torch.from_numpy(np_coord_tensor))\n",
        "\n",
        "        self.fcout = FCOutputModel()\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "\n",
        "    def forward(self, img, qst):\n",
        "        x = self.conv(img) ## x = (64 x 24 x 5 x 5)\n",
        "        \n",
        "        \"\"\"g\"\"\"\n",
        "        mb = x.size()[0]\n",
        "        n_channels = x.size()[1]\n",
        "        d = x.size()[2]\n",
        "        # x_flat = (64 x 25 x 24)\n",
        "        x_flat = x.view(mb,n_channels,d*d).permute(0,2,1)\n",
        "        \n",
        "        # add coordinates\n",
        "        x_flat = torch.cat([x_flat, self.coord_tensor], 2)\n",
        "\n",
        "        if self.relation_type == 'ternary':\n",
        "            # add question everywhere\n",
        "            qst = torch.unsqueeze(qst, 1) # (64x1x18)\n",
        "            qst = qst.repeat(1, 25, 1) # (64x25x18)\n",
        "            qst = torch.unsqueeze(qst, 1)  # (64x1x25x18)\n",
        "            qst = torch.unsqueeze(qst, 1)  # (64x1x1x25x18)\n",
        "\n",
        "            # cast all triples against each other\n",
        "            x_i = torch.unsqueeze(x_flat, 1)  # (64x1x25x26)\n",
        "            x_i = torch.unsqueeze(x_i, 3)  # (64x1x25x1x26)\n",
        "            x_i = x_i.repeat(1, 25, 1, 25, 1)  # (64x25x25x25x26)\n",
        "            \n",
        "            x_j = torch.unsqueeze(x_flat, 2)  # (64x25x1x26)\n",
        "            x_j = torch.unsqueeze(x_j, 2)  # (64x25x1x1x26)\n",
        "            x_j = x_j.repeat(1, 1, 25, 25, 1)  # (64x25x25x25x26)\n",
        "\n",
        "            x_k = torch.unsqueeze(x_flat, 1)  # (64x1x25x26)\n",
        "            x_k = torch.unsqueeze(x_k, 1)  # (64x1x1x25x26)\n",
        "            x_k = torch.cat([x_k, qst], 4)  # (64x1x1x25x26+18)\n",
        "            x_k = x_k.repeat(1, 25, 25, 1, 1)  # (64x25x25x25x26+18)\n",
        "\n",
        "            # concatenate all together\n",
        "            x_full = torch.cat([x_i, x_j, x_k], 4)  # (64x25x25x25x3*26+18)\n",
        "\n",
        "            # reshape for passing through network\n",
        "            x_ = x_full.view(mb * (d * d) * (d * d) * (d * d), (self.conv_size[0] + 2) * 3 + 18)  # (64*25*25*25x3*26+18) = (1.000.000, 96)\n",
        "        else:\n",
        "            # add question everywhere\n",
        "            qst = torch.unsqueeze(qst, 1)\n",
        "            qst = qst.repeat(1, 25, 1)\n",
        "            qst = torch.unsqueeze(qst, 2)\n",
        "\n",
        "            # cast all pairs against each other\n",
        "            x_i = torch.unsqueeze(x_flat, 1)  # (64x1x25x26+18)\n",
        "            x_i = x_i.repeat(1, 25, 1, 1)  # (64x25x25x26+18)\n",
        "            x_j = torch.unsqueeze(x_flat, 2)  # (64x25x1x26+18)\n",
        "            x_j = torch.cat([x_j, qst], 3)\n",
        "            x_j = x_j.repeat(1, 1, 25, 1)  # (64x25x25x26+18)\n",
        "            \n",
        "            # concatenate all together\n",
        "            x_full = torch.cat([x_i,x_j],3) # (64x25x25x2*26+18)\n",
        "        \n",
        "            # reshape for passing through network\n",
        "            x_ = x_full.view(mb * (d * d) * (d * d), (self.conv_size[0] + 2) * 2 + 18)  # (64*25*25x2*26*18) = (40.000, 70)\n",
        "            \n",
        "        x_ = self.g_fc1(x_)\n",
        "        x_ = F.relu(x_)\n",
        "        x_ = self.g_fc2(x_)\n",
        "        x_ = F.relu(x_)\n",
        "        x_ = self.g_fc3(x_)\n",
        "        x_ = F.relu(x_)\n",
        "        x_ = self.g_fc4(x_)\n",
        "        x_ = F.relu(x_)\n",
        "        \n",
        "        # reshape again and sum\n",
        "        if self.relation_type == 'ternary':\n",
        "            x_g = x_.view(mb, (d * d) * (d * d) * (d * d), 256)\n",
        "        else:\n",
        "            x_g = x_.view(mb, (d * d) * (d * d), 256)\n",
        "\n",
        "        x_g = x_g.sum(1).squeeze()\n",
        "        \n",
        "        \"\"\"f\"\"\"\n",
        "        x_f = self.f_fc1(x_g)\n",
        "        x_f = F.relu(x_f)\n",
        "        \n",
        "        return self.fcout(x_f)\n",
        "\n",
        "    def train_(self, input_img, input_qst, label):\n",
        "        self.optimizer.zero_grad()\n",
        "        if self.device.startswith('cuda'):\n",
        "            with autocast():\n",
        "                output = self(input_img, input_qst)\n",
        "                loss = F.nll_loss(output, label)\n",
        "        else:\n",
        "            output = self(input_img, input_qst)\n",
        "            loss = F.nll_loss(output, label)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        pred = output.data.max(1)[1]\n",
        "        correct = pred.eq(label.data).cpu().sum()\n",
        "        accuracy = correct * 100. / len(label)\n",
        "        return accuracy, loss\n",
        "        \n",
        "    def test_(self, input_img, input_qst, label):\n",
        "        if self.device.startswith('cuda'):\n",
        "            with autocast():\n",
        "                output = self(input_img, input_qst)\n",
        "                loss = F.nll_loss(output, label)\n",
        "        else:\n",
        "            output = self(input_img, input_qst)\n",
        "            loss = F.nll_loss(output, label)\n",
        "        pred = output.data.max(1)[1]\n",
        "        correct = pred.eq(label.data).cpu().sum()\n",
        "        accuracy = correct * 100. / len(label)\n",
        "        return accuracy, loss\n",
        "\n",
        "    def save_model(self, epoch):\n",
        "        torch.save(self.state_dict(), 'model/epoch_RN_{:02d}.pth'.format(epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPK4H2YE_Fsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f42a04c-5b1d-4310-94d8-c45d0654ff9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "bs = 32\n",
        "epochs = 40\n",
        "seed = 1\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print('Using device:', device)\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "model = RN(batch_size=bs, device=device)\n",
        "\n",
        "model_dirs = './model'\n",
        "input_img = torch.FloatTensor(bs, 3, 75, 75)\n",
        "input_qst = torch.FloatTensor(bs, 18)\n",
        "label = torch.LongTensor(bs)\n",
        "\n",
        "model.to(device)\n",
        "input_img = input_img.to(device)\n",
        "input_qst = input_qst.to(device)\n",
        "label = label.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4tkKUKWCL2i"
      },
      "outputs": [],
      "source": [
        "def tensor_data(data, i):\n",
        "    img = torch.from_numpy(np.asarray(data[0][bs*i:bs*(i+1)]))\n",
        "    qst = torch.from_numpy(np.asarray(data[1][bs*i:bs*(i+1)]))\n",
        "    ans = torch.from_numpy(np.asarray(data[2][bs*i:bs*(i+1)]))\n",
        "\n",
        "    input_img.data.resize_(img.size()).copy_(img)\n",
        "    input_qst.data.resize_(qst.size()).copy_(qst)\n",
        "    label.data.resize_(ans.size()).copy_(ans)\n",
        "\n",
        "\n",
        "def cvt_data_axis(data):\n",
        "    img = [e[0] for e in data]\n",
        "    qst = [e[1] for e in data]\n",
        "    ans = [e[2] for e in data]\n",
        "    return (img,qst,ans)\n",
        "\n",
        "\n",
        "def train(epoch, ternary, rel, norel):\n",
        "    model.train()\n",
        "\n",
        "    if not len(rel[0]) == len(norel[0]):\n",
        "        print('Not equal length for relation dataset and non-relation dataset.')\n",
        "        return\n",
        "    \n",
        "    random.shuffle(ternary)\n",
        "    random.shuffle(rel)\n",
        "    random.shuffle(norel)\n",
        "\n",
        "    ternary = cvt_data_axis(ternary)\n",
        "    rel = cvt_data_axis(rel)\n",
        "    norel = cvt_data_axis(norel)\n",
        "\n",
        "    acc_ternary = []\n",
        "    acc_rels = []\n",
        "    acc_norels = []\n",
        "\n",
        "    l_ternary = []\n",
        "    l_binary = []\n",
        "    l_unary = []\n",
        "\n",
        "    for batch_idx in range(len(rel[0]) // bs):\n",
        "        tensor_data(ternary, batch_idx)\n",
        "        accuracy_ternary, loss_ternary = model.train_(input_img, input_qst, label)\n",
        "        acc_ternary.append(accuracy_ternary.item())\n",
        "        l_ternary.append(loss_ternary.item())\n",
        "\n",
        "        tensor_data(rel, batch_idx)\n",
        "        accuracy_rel, loss_binary = model.train_(input_img, input_qst, label)\n",
        "        acc_rels.append(accuracy_rel.item())\n",
        "        l_binary.append(loss_binary.item())\n",
        "\n",
        "        tensor_data(norel, batch_idx)\n",
        "        accuracy_norel, loss_unary = model.train_(input_img, input_qst, label)\n",
        "        acc_norels.append(accuracy_norel.item())\n",
        "        l_unary.append(loss_unary.item())\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)] '\n",
        "                  'Ternary accuracy: {:.0f}% | Relations accuracy: {:.0f}% | Non-relations accuracy: {:.0f}%'.format(\n",
        "                   epoch,\n",
        "                   batch_idx * bs * 2,\n",
        "                   len(rel[0]) * 2,\n",
        "                   100. * batch_idx * bs / len(rel[0]),\n",
        "                   accuracy_ternary,\n",
        "                   accuracy_rel,\n",
        "                   accuracy_norel))\n",
        "        \n",
        "    avg_acc_ternary = sum(acc_ternary) / len(acc_ternary)\n",
        "    avg_acc_binary = sum(acc_rels) / len(acc_rels)\n",
        "    avg_acc_unary = sum(acc_norels) / len(acc_norels)\n",
        "\n",
        "    return avg_acc_ternary, avg_acc_binary, avg_acc_unary\n",
        "\n",
        "\n",
        "def test(epoch, ternary, rel, norel):\n",
        "    model.eval()\n",
        "\n",
        "    if not len(rel[0]) == len(norel[0]):\n",
        "        print('Not equal length for relation dataset and non-relation dataset.')\n",
        "        return\n",
        "    \n",
        "    ternary = cvt_data_axis(ternary)\n",
        "    rel = cvt_data_axis(rel)\n",
        "    norel = cvt_data_axis(norel)\n",
        "\n",
        "    accuracy_ternary = []\n",
        "    accuracy_rels = []\n",
        "    accuracy_norels = []\n",
        "\n",
        "    loss_ternary = []\n",
        "    loss_binary = []\n",
        "    loss_unary = []\n",
        "\n",
        "    for batch_idx in range(len(rel[0]) // bs):\n",
        "        tensor_data(ternary, batch_idx)\n",
        "        acc_ter, l_ter = model.test_(input_img, input_qst, label)\n",
        "        accuracy_ternary.append(acc_ter.item())\n",
        "        loss_ternary.append(l_ter.item())\n",
        "\n",
        "        tensor_data(rel, batch_idx)\n",
        "        acc_bin, l_bin = model.test_(input_img, input_qst, label)\n",
        "        accuracy_rels.append(acc_bin.item())\n",
        "        loss_binary.append(l_bin.item())\n",
        "\n",
        "        tensor_data(norel, batch_idx)\n",
        "        acc_un, l_un = model.test_(input_img, input_qst, label)\n",
        "        accuracy_norels.append(acc_un.item())\n",
        "        loss_unary.append(l_un.item())\n",
        "\n",
        "    accuracy_ternary = sum(accuracy_ternary) / len(accuracy_ternary)\n",
        "    accuracy_rel = sum(accuracy_rels) / len(accuracy_rels)\n",
        "    accuracy_norel = sum(accuracy_norels) / len(accuracy_norels)\n",
        "    print('\\n Test set: Ternary accuracy: {:.0f}% Binary accuracy: {:.0f}% | Unary accuracy: {:.0f}%\\n'.format(\n",
        "        accuracy_ternary, accuracy_rel, accuracy_norel))\n",
        "\n",
        "    return accuracy_ternary, accuracy_rel, accuracy_norel\n",
        "\n",
        "    \n",
        "def load_data():\n",
        "    print('loading data...')\n",
        "    dirs = './data'\n",
        "    filename = os.path.join(dirs, 'sort-of-clevr.pickle')\n",
        "    with open(filename, 'rb') as f:\n",
        "        train_datasets, test_datasets = pickle.load(f)\n",
        "    object_train = []\n",
        "    object_test = []\n",
        "    ternary_train = []\n",
        "    ternary_test = []\n",
        "    rel_train = []\n",
        "    rel_test = []\n",
        "    norel_train = []\n",
        "    norel_test = []\n",
        "    print('processing data...')\n",
        "\n",
        "    for img, objects, ternary, relations, norelations in train_datasets:\n",
        "        img = np.swapaxes(img, 0, 2)\n",
        "        object_train.append(objects)\n",
        "        for qst, ans in zip(ternary[0], ternary[1]):\n",
        "            ternary_train.append((img,qst,ans))\n",
        "        for qst,ans in zip(relations[0], relations[1]):\n",
        "            rel_train.append((img,qst,ans))\n",
        "        for qst,ans in zip(norelations[0], norelations[1]):\n",
        "            norel_train.append((img,qst,ans))\n",
        "\n",
        "    for img, objects, ternary, relations, norelations in test_datasets:\n",
        "        img = np.swapaxes(img, 0, 2)\n",
        "        object_test.append(objects)\n",
        "        for qst, ans in zip(ternary[0], ternary[1]):\n",
        "            ternary_test.append((img, qst, ans))\n",
        "        for qst,ans in zip(relations[0], relations[1]):\n",
        "            rel_test.append((img,qst,ans))\n",
        "        for qst,ans in zip(norelations[0], norelations[1]):\n",
        "            norel_test.append((img,qst,ans))\n",
        "    \n",
        "    return (object_train, object_test, ternary_train, ternary_test, rel_train, rel_test, norel_train, norel_test)\n",
        "\n",
        "\n",
        "def state_description(obj):\n",
        "    c = [\n",
        "        \"red\",\n",
        "        \"green\",\n",
        "        \"blue\",\n",
        "        \"orange\",\n",
        "        \"gray\",\n",
        "        \"yellow\"\n",
        "    ]\n",
        "    return pd.DataFrame([{\n",
        "        \"x\": o[1][0],\n",
        "        \"y\": o[1][1],\n",
        "        \"color\": c[o[0]],\n",
        "        \"shape\": \"circle\" if o[2] == \"c\" else \"rectage\"\n",
        "    } for o in obj])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "52BZCgT-bDcp",
        "outputId": "5d378247-c515-402e-93d7-7989c2b30bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data...\n",
            "processing data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    x   y   color    shape\n",
              "0  50  60     red   circle\n",
              "1   9  59   green   circle\n",
              "2  42  49    blue  rectage\n",
              "3  28  10  orange  rectage\n",
              "4  13  33    gray  rectage\n",
              "5  51  12  yellow  rectage"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-819648d6-b7aa-4918-a2bc-897fc11e96c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>color</th>\n",
              "      <th>shape</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>60</td>\n",
              "      <td>red</td>\n",
              "      <td>circle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>59</td>\n",
              "      <td>green</td>\n",
              "      <td>circle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42</td>\n",
              "      <td>49</td>\n",
              "      <td>blue</td>\n",
              "      <td>rectage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>10</td>\n",
              "      <td>orange</td>\n",
              "      <td>rectage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>33</td>\n",
              "      <td>gray</td>\n",
              "      <td>rectage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>51</td>\n",
              "      <td>12</td>\n",
              "      <td>yellow</td>\n",
              "      <td>rectage</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-819648d6-b7aa-4918-a2bc-897fc11e96c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-819648d6-b7aa-4918-a2bc-897fc11e96c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-819648d6-b7aa-4918-a2bc-897fc11e96c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "object_train, object_test, ternary_train, ternary_test, rel_train, rel_test, norel_train, norel_test = load_data()\n",
        "\n",
        "state_description(object_train[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.5 ('ldm')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "6cee02f5b6f69b62eef9d02181770a5082a43722aa50202691761ae71110baf6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}